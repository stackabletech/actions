---
name: Run Integration Test
description: |
  This action runs Stackable Operator integration tests on various platforms and
  Kubernetes distributions.
inputs:
  test-profile:
    description: Test profile to run
  replicated-api-token:
    description: Replicated API token (only needed if running on replicated)
    default: ""
  interu-version:
    description: Version of interu
    default: 0.1.0
  beku-version:
    description: Version of beku
    default: 0.0.8
  kuttl-version:
    description: Version of kubectl-kuttl
    default: 0.19.0
  stackablectl-version:
    description: Version of stackablectl
    default: 24.11.2
outputs:
  start-time:
    description: The date and time this integration test was started.
    value: ${{ steps.start-time.outputs.START_TIME }}
  end-time:
    description: The date and time this integration test finished.
    value: ${{ steps.end-time.outputs.END_TIME }}
runs:
  using: composite
  steps:
    - name: Extract Test and Instance Configuration
      env:
        INTERU_VERSION: ${{ inputs.interu-version }}
        TEST_PROFILE: ${{ inputs.test-profile }}
        GITHUB_DEBUG: ${{ runner.debug }}
      shell: bash
      run: |
        set -euo pipefail
        [ -n "$GITHUB_DEBUG" ] && set -x

        # Download interu
        curl -fsSL -o /tmp/interu "https://github.com/stackabletech/actions/releases/download/interu-$INTERU_VERSION/interu-x86_64-unknown-linux-gnu"
        sudo install -m 755 -t /usr/local/bin /tmp/interu

        # Run interu to expand parameters into GITHUB_ENV
        interu --instances "$GITHUB_ACTION_PATH/instances.yml" --check-test-definitions "$TEST_PROFILE" --output "$GITHUB_ENV"

    # Install all tools BEFORE creating the cluster, because if some of the tools fail to download
    # and are therefore not available, there is no need to create the cluster or run the tests,
    # because the tests can never run in the first place.

    # We don't need to install kubectl, kind or helm because it is already part of the installed
    # tools of the runner image.
    # See https://github.com/actions/runner-images/blob/main/images/ubuntu/scripts/build/install-kubernetes-tools.sh
    - name: Install kubectl-kuttl
      env:
        KUTTL_VERSION: ${{ inputs.kuttl-version }}
      shell: bash
      run: |
        set -euo pipefail

        curl -fsSL -o /tmp/kubectl-kuttl "https://github.com/kudobuilder/kuttl/releases/download/v$KUTTL_VERSION/kubectl-kuttl_${KUTTL_VERSION}_linux_x86_64"
        sudo install -m 755 -t /usr/local/bin /tmp/kubectl-kuttl

    # Python3 is already installed, if we ever need to specify the version, we can use the
    # setup-python action.
    # See https://github.com/actions/runner-images/blob/main/images/ubuntu/scripts/build/install-python.sh
    - name: Install beku
      env:
        BEKU_VERSION: ${{ inputs.beku-version }}
      shell: bash
      run: |
        set -euo pipefail
        pip install "beku-stackabletech==$BEKU_VERSION"

    # mikefarah/yq is already installed on the runner
    # See https://github.com/actions/runner-images/blob/main/images/ubuntu/scripts/build/install-yq.sh

    - name: Install stackablectl
      env:
        STACKABLECTL_VERSION: ${{ inputs.stackablectl-version }}
      shell: bash
      run: |
        set -euo pipefail

        curl -fsSL -o /tmp/stackablectl "https://github.com/stackabletech/stackable-cockpit/releases/download/stackablectl-$STACKABLECTL_VERSION/stackablectl-x86_64-unknown-linux-gnu"
        sudo install -m 755 -t /usr/local/bin /tmp/stackablectl

    - name: Install apt packages
      shell: bash
      run: |
        set -euo pipefail

        sudo apt update
        sudo apt install -y \
          gettext-base

    - name: Prepare Replicated Cluster
      if: env.KUBERNETES_DISTRIBUTION != 'ionos'
      id: prepare-replicated-cluster
      uses: replicatedhq/replicated-actions/create-cluster@77121785951d05387334b773644c356885191f14 # v1.16.2
      with:
        # See: https://github.com/replicatedhq/replicated-actions/tree/main/create-cluster#inputs
        api-token: ${{ inputs.replicated-api-token }}
        cluster-name: integration-test-${{ github.repository }}-${{ github.run_id }}
        kubernetes-distribution: ${{ env.INTERU_KUBERNETES_DISTRIBUTION }}
        kubernetes-version: ${{ env.INTERU_KUBERNETES_VERSION }}
        ttl: ${{ env.INTERU_CLUSTER_TTL }}
        node-groups: ${{ env.INTERU_NODE_GROUPS }}
        tags: |
          - key: kubernetes-distribution
            value: ${{ env.INTERU_KUBERNETES_DISTRIBUTION }}
          - key: triggered-by
            value: ${{ github.triggering_actor }}
          - key: test-set
            value: ${{ env.INTERU_TEST_RUN }}=${{ env.INTERU_TEST_PARAMETER }}
          - key: test-parallelism
            value: "${{ env.INTERU_TEST_PARALLELISM }}"

    - name: Set Replicated kubeconfig
      if: env.INTERU_KUBERNETES_DISTRIBUTION != 'ionos'
      env:
        KUBECONFIG: ${{ steps.prepare-replicated-cluster.outputs.cluster-kubeconfig }}
      shell: bash
      run: |
        set -euo pipefail
        mkdir ~/.kube
        echo "$KUBECONFIG" > ~/.kube/config

    - name: Extract Operator Name
      env:
        REPOSITORY: ${{ github.repository }}
      shell: bash
      run: |
        set -euo pipefail

        OPERATOR_NAME=$(echo "$REPOSITORY" | cut -d / -f 2 | sed 's/-operator//g')
        echo "OPERATOR_NAME=$OPERATOR_NAME" | tee -a "$GITHUB_ENV"

    - name: Install OpenTelemetry Operator
      shell: bash
      run: |
        set -euo pipefail

        echo "::group::kubectl apply"
        kubectl kustomize --enable-helm "${GITHUB_ACTION_PATH}/kustomize/bases/opentelemetry-operator" | kubectl apply -f -
        kubectl -n opentelemetry-operator wait --for condition=Progressing deploy/opentelemetry-operator --timeout=300s
        kubectl -n opentelemetry-operator wait --for condition=Available deploy/opentelemetry-operator --timeout=300s
        kubectl -n opentelemetry-operator get pods
        echo "::endgroup::"

    - name: Apply OpenTelemetry Collectors configurations
      shell: bash
      run: |
        set -euo pipefail

        echo "::group::kubectl apply"
        kubectl apply -k ${GITHUB_ACTION_PATH}/kustomize/overlays/replicated
        echo "Waiting a few seconds for the operator to create the deployment" && sleep 5
        kubectl -n opentelemetry-operator wait --for condition=Progressing deploy/replicated-kubernetes-events-collector --timeout=300s
        kubectl -n opentelemetry-operator wait --for condition=Available deploy/replicated-kubernetes-events-collector --timeout=300s
        kubectl -n opentelemetry-operator rollout status ds replicated-container-log-scrape-collector --timeout=300s
        echo "::endgroup::"
        echo "::group::kubectl get"
        kubectl -n opentelemetry-operator get opentelemetrycollectors
        kubectl -n opentelemetry-operator get pods
        echo "::endgroup::"

    - name: Record Test Start Time
      id: start-time
      shell: bash
      run: |
        echo "START_TIME=$(date +'%Y-%m-%dT%H:%M:%S')" | tee -a "$GITHUB_OUTPUT"

    - name: Run Integration Test (${{ env.INTERU_TEST_RUN }}=${{ env.INTERU_TEST_PARAMETER }}/${{ env.INTERU_TEST_PARALLELISM }})
      env:
        REF_NAME: ${{ github.ref_name }}
        GH_TOKEN: ${{ github.token }}
      shell: bash
      run: |
        set -euo pipefail

        OPERATOR_VERSION=$("$GITHUB_ACTION_PATH/../.scripts/get_operator_version.sh" "$REF_NAME")
        python ./scripts/run-tests --skip-tests --operator "$OPERATOR_NAME=$OPERATOR_VERSION"

        if [ "$INTERU_TEST_RUN" == "all" ]; then
          python ./scripts/run-tests --skip-release --log-level debug --parallel "$INTERU_TEST_PARALLELISM"
        else
          python ./scripts/run-tests --skip-release --log-level debug "--$INTERU_TEST_RUN" "$INTERU_TEST_PARAMETER" --parallel "$INTERU_TEST_PARALLELISM"
        fi

    - name: Record Test End Time
      id: end-time
      if: always()
      shell: bash
      run: |
        echo "END_TIME=$(date +'%Y-%m-%dT%H:%M:%S')" | tee -a "$GITHUB_OUTPUT"

    - name: Destroy Replicated Cluster
      if: env.KUBERNETES_DISTRIBUTION != 'ionos' && always()
      # If the creation of the cluster failed, we don't want to error and abort
      continue-on-error: true
      uses: replicatedhq/replicated-actions/remove-cluster@77121785951d05387334b773644c356885191f14 # v1.16.2
      with:
        # See: https://github.com/replicatedhq/replicated-actions/tree/main/remove-cluster#inputs
        api-token: ${{ inputs.replicated-api-token }}
        cluster-id: ${{ steps.prepare-replicated-cluster.outputs.cluster-id }}
